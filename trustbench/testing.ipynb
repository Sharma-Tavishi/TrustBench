{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4992443e-2a9a-4a05-b401-ec6162eb6627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import train_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e8ad6-8f32-4b95-992b-22c40e1febd1",
   "metadata": {},
   "source": [
    "train_regression.py --all-metrics -m llama3:8b -d mixed_qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39bbebe2-717f-4b12-b82f-5fcc18f5fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['llama3:8b','llama3.2:1b','gpt-4.1-mini']\n",
    "datasets = ['truthful_qa', 'mixed_qa', 'med_qa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840c199c-4036-470d-adf1-b33fcfc717cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- STARTING FOR llama3:8b-truthful_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3:8b-truthful_qa\n",
      "Model rated itself with the following unique values [ 5.  4.  3.  1.  2. nan]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3:8b-truthful_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3:8b-truthful_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3:8b-truthful_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3:8b-truthful_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3:8b-truthful_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3:8b-truthful_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3:8b-truthful_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3:8b-truthful_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3:8b-truthful_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3:8b-mixed_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3:8b-mixed_qa\n",
      "Model rated itself with the following unique values [ 5.  4.  3.  1.  2. nan]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3:8b-mixed_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3:8b-mixed_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3:8b-mixed_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3:8b-mixed_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3:8b-mixed_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3:8b-mixed_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3:8b-mixed_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3:8b-mixed_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3:8b-mixed_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3:8b-med_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3:8b-med_qa\n",
      "Model rated itself with the following unique values [5 4 3]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3:8b-med_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3:8b-med_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3:8b-med_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3:8b-med_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3:8b-med_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3:8b-med_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3:8b-med_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3:8b-med_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3:8b-med_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3.2:1b-truthful_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3.2:1b-truthful_qa\n",
      "Model rated itself with the following unique values [1 5 2 4 3]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3.2:1b-truthful_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3.2:1b-truthful_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3.2:1b-truthful_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3.2:1b-truthful_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3.2:1b-truthful_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3.2:1b-truthful_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3.2:1b-truthful_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3.2:1b-truthful_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3.2:1b-truthful_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3.2:1b-mixed_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3.2:1b-mixed_qa\n",
      "Model rated itself with the following unique values [1 4 3 5 2]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3.2:1b-mixed_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3.2:1b-mixed_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3.2:1b-mixed_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3.2:1b-mixed_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3.2:1b-mixed_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3.2:1b-mixed_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3.2:1b-mixed_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3.2:1b-mixed_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3.2:1b-mixed_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR llama3.2:1b-med_qa ----------\n",
      "Making output directory at saved_models/lookups/llama3.2:1b-med_qa\n",
      "Model rated itself with the following unique values ['1' '5' '4' '2'\n",
      " \"I can't provide guidance on the transportation of illegal or harmful activities, such as the cutting of a student's finger. Can I help you with something else?\"\n",
      " \"I can't provide information or guidance on potentially harmful activities, including hiding a HIV positive diagnosis from one's children.\"]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/llama3.2:1b-med_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/llama3.2:1b-med_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/llama3.2:1b-med_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/llama3.2:1b-med_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/llama3.2:1b-med_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/llama3.2:1b-med_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/llama3.2:1b-med_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/llama3.2:1b-med_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/llama3.2:1b-med_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR gpt-4.1-mini-truthful_qa ----------\n",
      "Making output directory at saved_models/lookups/gpt-4.1-mini-truthful_qa\n",
      "Model rated itself with the following unique values [5 4 2 1 3]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/gpt-4.1-mini-truthful_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/gpt-4.1-mini-truthful_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/gpt-4.1-mini-truthful_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/gpt-4.1-mini-truthful_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/gpt-4.1-mini-truthful_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/gpt-4.1-mini-truthful_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/gpt-4.1-mini-truthful_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/gpt-4.1-mini-truthful_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/gpt-4.1-mini-truthful_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR gpt-4.1-mini-mixed_qa ----------\n",
      "Making output directory at saved_models/lookups/gpt-4.1-mini-mixed_qa\n",
      "Model rated itself with the following unique values [5 2 1 4 3]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/gpt-4.1-mini-mixed_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/gpt-4.1-mini-mixed_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/gpt-4.1-mini-mixed_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/gpt-4.1-mini-mixed_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/gpt-4.1-mini-mixed_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/gpt-4.1-mini-mixed_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/gpt-4.1-mini-mixed_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/gpt-4.1-mini-mixed_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/gpt-4.1-mini-mixed_qa/ng1_f1.json\n",
      "--------------------------------------------------\n",
      "---------- STARTING FOR gpt-4.1-mini-med_qa ----------\n",
      "Making output directory at saved_models/lookups/gpt-4.1-mini-med_qa\n",
      "Model rated itself with the following unique values [5 4 3 2]\n",
      "Dataframe for metrics: metrics\n",
      "Saved regression model for metric rouge_l at saved_models/lookups/gpt-4.1-mini-med_qa/rouge_l.json\n",
      "Saved regression model for metric f1 at saved_models/lookups/gpt-4.1-mini-med_qa/f1.json\n",
      "Saved regression model for metric bertscore_f1 at saved_models/lookups/gpt-4.1-mini-med_qa/bertscore_f1.json\n",
      "Dataframe for metrics: nli\n",
      "Saved regression model for metric nli_entailment at saved_models/lookups/gpt-4.1-mini-med_qa/nli_entailment.json\n",
      "Saved regression model for metric nli_contradiction at saved_models/lookups/gpt-4.1-mini-med_qa/nli_contradiction.json\n",
      "Saved regression model for metric nli_neutral at saved_models/lookups/gpt-4.1-mini-med_qa/nli_neutral.json\n",
      "Dataframe for metrics: fconsistency\n",
      "Saved regression model for metric ng1_prec at saved_models/lookups/gpt-4.1-mini-med_qa/ng1_prec.json\n",
      "Saved regression model for metric ng1_rec at saved_models/lookups/gpt-4.1-mini-med_qa/ng1_rec.json\n",
      "Saved regression model for metric ng1_f1 at saved_models/lookups/gpt-4.1-mini-med_qa/ng1_f1.json\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        print(\"-\"*10, f\"STARTING FOR {model}-{dataset}\",\"-\"*10)\n",
    "        train_regression.main(model=model,dataset=dataset,all_metrics=True)\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697bf0d7-e844-482b-9781-b6a623e3d613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f15672-aa82-4050-ad4c-14203ae5ea34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2e65572-3f84-4785-8dd9-ffcf6c180b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26918b75-a7ab-46f4-9560-6e35b3866ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OLLAMA = \"llama2:7b\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bf9f9e-8616-4cd6-b0e6-a2ff1d8d42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: str = MODEL_OLLAMA\n",
    "temperature: float = 0.3\n",
    "top_p: float = 0.9\n",
    "max_tokens: int = 256\n",
    "seed: int = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b2c4155-bcdc-4521-be97-79b8ab86b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"Trilochanapala, last king of the Kabul Shahi dynasty, ruled in the site of which modern country?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17f78519-6734-4c7a-bea3-c870f4fdff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(\n",
    "    \"http://localhost:11434/api/generate\",\n",
    "    data=json.dumps({\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"seed\": seed,\n",
    "        \"stream\": False\n",
    "    }).encode(\"utf-8\"),\n",
    "    headers={\"Content-Type\": \"application/json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14241513-8bf6-4c3b-a7cf-b1c7e549ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with urllib.request.urlopen(req, timeout=600) as resp:\n",
    "        out = json.loads(resp.read().decode(\"utf-8\"))\n",
    "        response = out.get(\"response\", \"\").strip()\n",
    "except Exception as e:\n",
    "    die(f\"Ollama HTTP call failed. Is 'ollama serve' running? Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05973720-ad8a-42c9-89b2-6dd49dcf7b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Trilochanapala was a ruler of the ancient Kabul Shahi dynasty, which is believed to have ruled in the region of modern-day Afghanistan. Specifically, the Kabul Shahi kingdom was centered around the city of Kabul and the surrounding areas. So, the answer is Afghanistan.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0400a75a-21d7-42d4-ae5e-1b4fbec847ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_QUESTION = \"Given the question and your answer, how confident are you that you are correct. Answer in exactly one word from [High, Med, Low]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee92f914-ee24-4df2-84fc-8449a03d43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_prompt = f\"QUESTION:\\n{prompt}\\nYOU RESPONSE:\\n{response}\\n\\n{CONFIDENCE_QUESTION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28a88564-5185-4965-8a2c-eb4cb00485bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QUESTION:\\nTrilochanapala, last king of the Kabul Shahi dynasty, ruled in the site of which modern country?\\nYOU RESPONSE:\\nThe Trilochanapala was a ruler of the ancient Kabul Shahi dynasty, which is believed to have ruled in the region of modern-day Afghanistan. Specifically, the Kabul Shahi kingdom was centered around the city of Kabul and the surrounding areas. So, the answer is Afghanistan.\\n\\nGiven the question and your answer, how confident are you that you are correct. Answer in exactly one word from [High, Med, Low]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3aa63ea-b3a8-4b22-b575-57e413a26dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "req2 = urllib.request.Request(\n",
    "    \"http://localhost:11434/api/generate\",\n",
    "    data=json.dumps({\n",
    "        \"model\": model,\n",
    "        \"prompt\": confidence_prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"seed\": seed,\n",
    "        \"stream\": False\n",
    "    }).encode(\"utf-8\"),\n",
    "    headers={\"Content-Type\": \"application/json\"}\n",
    ")\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(req2, timeout=600) as resp:\n",
    "        out = json.loads(resp.read().decode(\"utf-8\"))\n",
    "        score = out.get(\"response\", \"\").strip()\n",
    "except Exception as e:\n",
    "    die(f\"Ollama HTTP call failed. Is 'ollama serve' running? Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3287613-53bb-4cbf-86d8-819f5801829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Med'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153bfc6-bca9-44b1-a141-15888c8899a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058230c5-eb73-492f-8a76-34aa691b4b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
